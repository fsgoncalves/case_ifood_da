{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93d65763",
   "metadata": {},
   "source": [
    "## Configurações iniciais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18098b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('D:\\\\__case_ifood\\\\notebooks\\\\utils') # Defina aqui a pasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90029bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import utils\n",
    "\n",
    "# Recarregar o módulo 'utils'\n",
    "importlib.reload(utils)\n",
    "\n",
    "from utils import get_bq_client, send_parquets_to_bigquery, credencial_gcp, pasta_projeto, semanas, bigquery, service_account, pl, pd, datetime, gc, os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a3f7c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pasta_projeto = \"D:\\\\__case_ifood\"\n",
    "\n",
    "# Caminho do arquivo JSON da conta de serviço\n",
    "#credencial_gcp = os.path.join(pasta_projeto,\"case-ifood-fsg-6f1d7cf34e08.json\")\n",
    "\n",
    "# Autenticando\n",
    "credencial = service_account.Credentials.from_service_account_file(credencial_gcp)\n",
    "\n",
    "# Cliente BigQuery\n",
    "client = get_bq_client() #bigquery.Client(credentials=credencial, project=\"case-ifood-fsg\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65a1a02",
   "metadata": {},
   "source": [
    "#### Filtro para otimizar o download da tabela no BQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe78874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lendo semana: 2018-12-02\n",
      "Arquivo salvo: D:\\__case_ifood\\sales_2018-12-02.parquet\n",
      "Lendo semana: 2018-12-09\n",
      "Arquivo salvo: D:\\__case_ifood\\sales_2018-12-09.parquet\n",
      "Lendo semana: 2018-12-16\n",
      "Arquivo salvo: D:\\__case_ifood\\sales_2018-12-16.parquet\n",
      "Lendo semana: 2018-12-23\n",
      "Arquivo salvo: D:\\__case_ifood\\sales_2018-12-23.parquet\n",
      "Lendo semana: 2018-12-30\n",
      "Arquivo salvo: D:\\__case_ifood\\sales_2018-12-30.parquet\n",
      "Lendo semana: 2019-01-06\n",
      "Arquivo salvo: D:\\__case_ifood\\sales_2019-01-06.parquet\n",
      "Lendo semana: 2019-01-13\n",
      "Arquivo salvo: D:\\__case_ifood\\sales_2019-01-13.parquet\n",
      "Lendo semana: 2019-01-20\n",
      "Arquivo salvo: D:\\__case_ifood\\sales_2019-01-20.parquet\n",
      "Lendo semana: 2019-01-27\n",
      "Arquivo salvo: D:\\__case_ifood\\sales_2019-01-27.parquet\n"
     ]
    }
   ],
   "source": [
    "# Realizando o download da tabela e salvando em diversos arquivos parquet\n",
    "\n",
    "system_hour = pd.Timestamp\n",
    "\n",
    "for semana in semanas:\n",
    "    print(f\"Lendo semana: {semana}\")\n",
    "\n",
    "    qry = f\"\"\"\n",
    "         WITH \n",
    "         -- Busca a maior data de inserção de registros na tabela\n",
    "            order_last_date AS (\n",
    "                SELECT\n",
    "                        MAX(insert_date) last_date\n",
    "                FROM silver.order\n",
    "                ),\n",
    "\n",
    "        -- Seleciona as colunas e as linhas necessárias, filtrando pelos registros inseridos por ultimo\n",
    "            tbl_order AS (\n",
    "                SELECT \n",
    "                        o.order_id,\n",
    "                        o.order_created_at,\n",
    "                        o.order_total_amount,\n",
    "                        o.customer_id,\n",
    "                        o.cpf,\n",
    "                        o.customer_name,\n",
    "                        o.delivery_address_district,\n",
    "                        o.delivery_address_city,\n",
    "                        o.delivery_address_state,\n",
    "                        o.delivery_address_country,\n",
    "                        o.merchant_id,\n",
    "                        o.order_scheduled,\n",
    "                        o.order_scheduled_date,\n",
    "                        o.origin_platform,\n",
    "                        CAST(DATE(DATE_TRUNC(o.order_created_at,week)) AS STRING) AS semana \n",
    "                FROM `silver.order` o\n",
    "                INNER JOIN order_last_date old\n",
    "                    ON o.insert_date = old.last_date\n",
    "                ),\n",
    "\n",
    "        -- Busca a maior data de inserção de registros na tabela\n",
    "            consumer_last_date AS (\n",
    "                SELECT\n",
    "                        MAX(insert_date) last_date\n",
    "                FROM silver.consumer c\n",
    "                ),\n",
    "\n",
    "        -- Seleciona as colunas e as linhas necessárias, filtrando pelos registros inseridos por ultimo\n",
    "            tbl_consumer AS (\n",
    "                SELECT\n",
    "                        c.customer_id,\n",
    "                        c.customer_name,\n",
    "                        c.created_at AS customer_created_at,\n",
    "                        c.active AS customer_active,\n",
    "                        CONCAT(c.customer_phone_area,'-',c.customer_phone_number) AS customer_phone,\n",
    "                        c.language AS customer_language,\n",
    "                FROM silver.consumer c\n",
    "                INNER JOIN consumer_last_date cld\n",
    "                    ON c.insert_date = cld.last_date\n",
    "                ),\n",
    "                \n",
    "        -- Busca a maior data de inserção de registros na tabela\n",
    "            merchants_last_date AS (\n",
    "                SELECT\n",
    "                        MAX(insert_date) last_date\n",
    "                FROM silver.merchants\n",
    "                ),\n",
    "            \n",
    "        -- Seleciona as colunas e as linhas necessárias, filtrando pelos registros inseridos por ultimo\n",
    "            tbl_merchants AS (\n",
    "                SELECT\n",
    "                        m.merchant_id,\n",
    "                        m.created_at AS merchant_created_at,\n",
    "                        m.enabled AS merchant_enabled,\n",
    "                        m.price_range,\n",
    "                        m.average_ticket,\n",
    "                        m.takeout_time,\n",
    "                        m.delivery_time,\n",
    "                        m.minimum_order_value,\n",
    "                        m.merchant_city,\n",
    "                        m.merchant_state\n",
    "                FROM silver.merchants m\n",
    "                INNER JOIN merchants_last_date mld\n",
    "                    ON m.insert_date = mld.last_date\n",
    "                ),\n",
    "\n",
    "        -- Busca a maior data de inserção de registros na tabela\n",
    "            ab_test_last_date AS (\n",
    "                SELECT\n",
    "                        MAX(insert_date) last_date\n",
    "                FROM silver.ab_test\n",
    "                ),\n",
    "\n",
    "        -- Seleciona as colunas e as linhas necessárias, filtrando pelos registros inseridos por ultimo\n",
    "            tbl_ab_test AS (\n",
    "                SELECT\n",
    "                        ab.customer_id,\n",
    "                        ab.is_target\n",
    "                FROM silver.ab_test ab\n",
    "                INNER JOIN ab_test_last_date abl\n",
    "                    ON ab.insert_date = abl.last_date\n",
    "                ),\n",
    "\n",
    "        -- Busca a maior data de inserção de registros na tabela\n",
    "            order_details_last_date AS (\n",
    "                SELECT\n",
    "                        MAX(insert_date) last_date\n",
    "                FROM silver.order_details od\n",
    "                ),\n",
    "\n",
    "        -- Seleciona as colunas e as linhas necessárias, filtrando pelos registros inseridos por ultimo\n",
    "            tbl_order_details AS (\n",
    "                SELECT\n",
    "                        od.order_id,\n",
    "                        od.cpf,\n",
    "                        od.name AS product,\n",
    "                        od.quantity,\n",
    "                        od.unitPrice,\n",
    "                        od.addition,\n",
    "                        od.discount,\n",
    "                        od.type AS product_type,\n",
    "                        od.sequence,\n",
    "                FROM silver.order_details od\n",
    "                INNER JOIN order_details_last_date odl\n",
    "                    ON od.insert_date = odl.last_date\n",
    "                ),\n",
    "\n",
    "        -- Monta a tabela final\n",
    "                tabela AS (\n",
    "                            SELECT \n",
    "                                o.order_id,\n",
    "                                o.order_created_at,\n",
    "                                od.product,\n",
    "                                od.quantity,\n",
    "                                od.unitPrice,\n",
    "                                od.addition,\n",
    "                                od.discount,\n",
    "                                o.order_total_amount,\n",
    "                                od.product_type,\n",
    "                                od.sequence,\n",
    "                                o.customer_id,\n",
    "                                o.cpf,\n",
    "                                COALESCE(c.customer_name, o.customer_name) AS customer_name,\n",
    "                                c.customer_created_at,\n",
    "                                c.customer_active,\n",
    "                                c.customer_phone,\n",
    "                                ab.is_target,\n",
    "                                c.customer_language,\n",
    "                                o.delivery_address_district,\n",
    "                                o.delivery_address_city,\n",
    "                                o.delivery_address_state,\n",
    "                                o.delivery_address_country,\n",
    "                                o.merchant_id,\n",
    "                                m.merchant_created_at,\n",
    "                                m.merchant_enabled,\n",
    "                                m.price_range,\n",
    "                                m.average_ticket,\n",
    "                                m.takeout_time,\n",
    "                                m.delivery_time,\n",
    "                                m.minimum_order_value,\n",
    "                                m.merchant_city,\n",
    "                                m.merchant_state,\n",
    "                                IF(od.order_id IS NULL, FALSE, TRUE) has_details,\n",
    "                                o.order_scheduled,\n",
    "                                o.order_scheduled_date,\n",
    "                                o.origin_platform,\n",
    "                                o.semana \n",
    "                            FROM tbl_order o\n",
    "                            LEFT JOIN tbl_consumer c \n",
    "                                ON o.customer_id = c.customer_id\n",
    "                            LEFT JOIN tbl_merchants m \n",
    "                                ON o.merchant_id = m.merchant_id\n",
    "                            LEFT JOIN tbl_ab_test ab \n",
    "                                ON o.customer_id = ab.customer_id\n",
    "                            LEFT JOIN tbl_order_details od \n",
    "                                ON  o.order_id = od.order_id \n",
    "                                AND o.cpf = od.cpf\n",
    "                )\n",
    "        SELECT * EXCEPT(semana)\n",
    "        FROM tabela\n",
    "        WHERE semana = '{semana}'\n",
    "    \"\"\"\n",
    "\n",
    "    result = client.query(qry)\n",
    "    arrow_table = result.to_arrow()\n",
    "    df = pl.from_arrow(arrow_table)\n",
    "\n",
    "    # Salva parquet na pasta do projeto\n",
    "    nome_arquivo = f\"sales_{semana}.parquet\"\n",
    "    caminho_arquivo = os.path.join(pasta_projeto, nome_arquivo)\n",
    "    df.write_parquet(caminho_arquivo)\n",
    "\n",
    "    print(f\"Arquivo salvo: {caminho_arquivo}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "060fce15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "286"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df\n",
    "del arrow_table\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32e7930a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lendo arquivo: sales_2018-12-02.parquet\n",
      "Enviando para BigQuery: sales_2018-12-02.parquet\n",
      "Dataset 'case-ifood-fsg.gold' pronto.\n",
      "Convertido de Polars para Pandas.\n",
      "Enviando chunk 1/1 com 940370 linhas...\n",
      "Tabela 'case-ifood-fsg.gold.sales' carregada com 940370 linhas.\n",
      "Lendo arquivo: sales_2018-12-09.parquet\n",
      "Enviando para BigQuery: sales_2018-12-09.parquet\n",
      "Dataset 'case-ifood-fsg.gold' pronto.\n",
      "Convertido de Polars para Pandas.\n",
      "Enviando chunk 1/2 com 1000000 linhas...\n",
      "Enviando chunk 2/2 com 369852 linhas...\n",
      "Tabela 'case-ifood-fsg.gold.sales' carregada com 1369852 linhas.\n",
      "Lendo arquivo: sales_2018-12-16.parquet\n",
      "Enviando para BigQuery: sales_2018-12-16.parquet\n",
      "Dataset 'case-ifood-fsg.gold' pronto.\n",
      "Convertido de Polars para Pandas.\n",
      "Enviando chunk 1/2 com 1000000 linhas...\n",
      "Enviando chunk 2/2 com 228143 linhas...\n",
      "Tabela 'case-ifood-fsg.gold.sales' carregada com 1228143 linhas.\n",
      "Lendo arquivo: sales_2018-12-23.parquet\n",
      "Enviando para BigQuery: sales_2018-12-23.parquet\n",
      "Dataset 'case-ifood-fsg.gold' pronto.\n",
      "Convertido de Polars para Pandas.\n",
      "Enviando chunk 1/2 com 1000000 linhas...\n",
      "Enviando chunk 2/2 com 233989 linhas...\n",
      "Tabela 'case-ifood-fsg.gold.sales' carregada com 1233989 linhas.\n",
      "Lendo arquivo: sales_2018-12-30.parquet\n",
      "Enviando para BigQuery: sales_2018-12-30.parquet\n",
      "Dataset 'case-ifood-fsg.gold' pronto.\n",
      "Convertido de Polars para Pandas.\n",
      "Enviando chunk 1/2 com 1000000 linhas...\n",
      "Enviando chunk 2/2 com 271347 linhas...\n",
      "Tabela 'case-ifood-fsg.gold.sales' carregada com 1271347 linhas.\n",
      "Lendo arquivo: sales_2019-01-06.parquet\n",
      "Enviando para BigQuery: sales_2019-01-06.parquet\n",
      "Dataset 'case-ifood-fsg.gold' pronto.\n",
      "Convertido de Polars para Pandas.\n",
      "Enviando chunk 1/2 com 1000000 linhas...\n",
      "Enviando chunk 2/2 com 78522 linhas...\n",
      "Tabela 'case-ifood-fsg.gold.sales' carregada com 1078522 linhas.\n",
      "Lendo arquivo: sales_2019-01-13.parquet\n",
      "Enviando para BigQuery: sales_2019-01-13.parquet\n",
      "Dataset 'case-ifood-fsg.gold' pronto.\n",
      "Convertido de Polars para Pandas.\n",
      "Enviando chunk 1/2 com 1000000 linhas...\n",
      "Enviando chunk 2/2 com 134935 linhas...\n",
      "Tabela 'case-ifood-fsg.gold.sales' carregada com 1134935 linhas.\n",
      "Lendo arquivo: sales_2019-01-20.parquet\n",
      "Enviando para BigQuery: sales_2019-01-20.parquet\n",
      "Dataset 'case-ifood-fsg.gold' pronto.\n",
      "Convertido de Polars para Pandas.\n",
      "Enviando chunk 1/2 com 1000000 linhas...\n",
      "Enviando chunk 2/2 com 167448 linhas...\n",
      "Tabela 'case-ifood-fsg.gold.sales' carregada com 1167448 linhas.\n",
      "Lendo arquivo: sales_2019-01-27.parquet\n",
      "Enviando para BigQuery: sales_2019-01-27.parquet\n",
      "Dataset 'case-ifood-fsg.gold' pronto.\n",
      "Convertido de Polars para Pandas.\n",
      "Enviando chunk 1/1 com 922649 linhas...\n",
      "Tabela 'case-ifood-fsg.gold.sales' carregada com 922649 linhas.\n"
     ]
    }
   ],
   "source": [
    "# Parametros necessários para enviar os arquivos Parquet para o BigQuery\n",
    "dataset_nome = \"gold\"\n",
    "tabela_nome = \"sales\"\n",
    "\n",
    "# Variável criada para garantir que os registros inseridos sejam no mesmo momento e não causar problema no particionamento\n",
    "var_timestamp = datetime.datetime.now(datetime.UTC)\n",
    "\n",
    "# Inserindo o DataFrame no BigQuery\n",
    "send_parquets_to_bigquery(pasta_projeto, dataset_nome, tabela_nome, client, var_timestamp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
